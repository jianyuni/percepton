import functools
import operator

class Perceptron(object):
    def __init__(self, x_num, activator):
        # init function which can be activated by number of input and function of activator
        self.activator = activator
        # initize w and b
        self.weights = [0.0,0.0]
        self.bias = 0.0
    def printstuff(self):
        print(self.weights,'and', self.bias)
        return self.weights,self.bias
    def predict(self, input_vec):
        return self.activator(functools.reduce(lambda a, b: a+b, map(lambda t: t[0]*t[1], zip(input_vec, self.weights)), 0.0) + self.bias)

    def train(self, input_vecs, labels, iteration, rate):
        for i in range(iteration):
            self._one_iteration(input_vecs, labels, rate)
    def _one_iteration(self, input_vecs, labels, rate):
    
        samples = zip(input_vecs, labels)
       
        for (input_vec, label) in samples:
            output = self.predict(input_vec)
            self._update_weights(input_vec, output, label, rate)
    def _update_weights(self, input_vec, output, label, rate):
        delta = label - output
        self.weights = list(map(
            lambda t: t[1] + rate * delta * t[0],
            zip(input_vec, self.weights)))
        self.bias += rate * delta
        print(self.weights)


def f(x):
    #define function f which is activator
    return 1 if x > 0 else 0
def get_training_dataset():
    input_vecs = [[1,1], [0,0], [1,0], [0,1]]
    labels = [1, 0, 0, 0]
    return input_vecs, labels    
def train_and_perceptron():
    p = Perceptron(2, f)
    # 训练，迭代10轮, 学习速率为0.1
    input_vecs, labels = get_training_dataset()
    p.train(input_vecs, labels, 10, 0.1)
    return p
if __name__ == '__main__': 
    p = train_and_perceptron()
    p.printstuff()
    print (p.predict([1, 1]))
    print (p.predict([0, 0]))
    print (p.predict([1, 0]))
    print (p.predict([0, 1]))
